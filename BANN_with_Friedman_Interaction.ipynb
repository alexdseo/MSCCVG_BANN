{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l21_norm(W):\n",
    "    # Computes the L21 norm of a symbolic matrix W\n",
    "    return tf.reduce_sum(tf.norm(W, axis=1))\n",
    "\n",
    "def group_regularization(v):\n",
    "    # Computes a group regularization loss from a list of weight matrices corresponding\n",
    "    # to the different layers\n",
    "    const_coeff = lambda W: tf.sqrt(tf.cast(W.get_shape().as_list()[1], tf.float32))\n",
    "    return tf.reduce_sum([tf.multiply(const_coeff(W), l21_norm(W)) for W in v if 'bias' not in W.name])\n",
    "\n",
    "def group_regularization_player(v):\n",
    "\tconst_coeff = lambda W: tf.sqrt(tf.cast(W.get_shape().as_list()[1], tf.float32))\n",
    "\treturn tf.reduce_sum(tf.multiply(const_coeff(v), l21_norm(v)))\n",
    "\n",
    "def custom_group_regularization_player(v, g_scalevec):\n",
    "\t#const_coeff = lambda W: tf.sqrt(tf.cast(W.get_shape().as_list()[1], tf.float32))\n",
    "\treturn tf.reduce_sum(tf.multiply(tf.norm(v, axis=1), g_scalevec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def friedman_suite(x):\n",
    "\treturn 10 * np.sin(np.pi * x[0] * x[1]) + 20 * (x[2] - 0.5)**2 + 10 * x[3] + 5 * x[4]\n",
    "\n",
    "def get_grd_importance(iXtest):\n",
    "\tnsamples = iXtest.shape[0]\n",
    "\tisum = 0.0\n",
    "\tfor i in range(nsamples):\n",
    "\t\tisum = isum + friedman_suite(iXtest[i, :])\n",
    "\tisum = isum * 1.0 / nsamples\n",
    "\treturn isum\n",
    "\n",
    "def f11_suite(x):\n",
    "    interaction1 = 10 * np.exp(x[:, 0]*x[:, 1])\n",
    "    interaction4 = 2 * np.arcsin(x[:, 8] * x[:, 9])\n",
    "    y=interaction1 + interaction4\n",
    "    return y\n",
    "\n",
    "def get_grd_importance_f(iXtest):\n",
    "\tisum = f11_suite(iXtest)\n",
    "\treturn np.mean(isum)\n",
    "\n",
    "def get_grd_importance_f4(iXtest):\n",
    "\tisum = f4_suite(iXtest)\n",
    "\treturn np.mean(isum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nums = 10\n",
    "zzelem = 0\n",
    "ffelem = np.zeros((nums, 1))\n",
    "sselem = np.zeros((nums, nums))\n",
    "ttelem = np.zeros((nums, nums, nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variance_order(tXtest, nums, simu):\n",
    "\tiXtest = tXtest.copy()\n",
    "\tzzelem = simu.eval(feed_dict={X:iXtest})\n",
    "\tffelem = np.zeros((nums, 1))\n",
    "\tx0 = np.linspace(0, 1, nums)\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, i] = x0[i] #bug\n",
    "\t\tffelem[i] = simu.eval(feed_dict={X:iXtest})\n",
    "\t\tiXtest = tXtest.copy()\n",
    "\tsselem = np.zeros((nums, nums))\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, i] = x0[i] #bug\n",
    "\t\tfor j in range(i+1, nums):\n",
    "\t\t\tiXtest[:, j] = x0[j]\n",
    "\t\t\tsselem[i, j] = simu.eval(feed_dict={X:iXtest})\n",
    "\t\t\tiXtest = tXtest.copy()\n",
    "\tttelem = np.zeros((nums, nums, nums))\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, i] = x0[i]\n",
    "\t\tfor j in range(i + 1, nums):\n",
    "\t\t\tiXtest[:, j] = x0[j]\n",
    "\t\t\tfor k in range(j + 1, nums):\n",
    "\t\t\t\tiXtest[:, k] = x0[k]\n",
    "\t\t\t\tttelem[i, j, k] = simu.eval(feed_dict={X:iXtest})\n",
    "\t\t\t\tiXtest = tXtest.copy()\n",
    "\n",
    "def get_1interaction(tXtest, nums, simu, pid):\n",
    "\tiXtest = tXtest.copy()\n",
    "\tmelem = simu.eval(feed_dict={X:iXtest})\n",
    "\tstrength = 0\n",
    "\tx0 = np.linspace(0, 1, nums)\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pid] = x0[i]\n",
    "\t\tselem = simu.eval(feed_dict={X:iXtest})\n",
    "\t\tstrength = strength + np.power(selem - melem, 2)\n",
    "\tstg = np.sqrt(strength * 1.0 / nums)\n",
    "\treturn stg\n",
    "\n",
    "def get_2importance(tXtest, nums, simu, pairs):\n",
    "\tiXtest = tXtest.copy()\n",
    "\tzelem = simu.eval(feed_dict={X:iXtest})\n",
    "\tfelem1 = np.zeros((nums, 1))\n",
    "\tfelem2 = np.zeros((nums, 1))\n",
    "\tx0 = np.linspace(0, 1, nums)\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pairs[0]] = x0[i]\n",
    "\t\tfelem1[i] = simu.eval(feed_dict={X:iXtest})\n",
    "\t\tiXtest = tXtest.copy()\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pairs[1]] = x0[i]\n",
    "\t\tfelem2[i] = simu.eval(feed_dict={X:iXtest})\n",
    "\t\tiXtest = tXtest.copy()\n",
    "\tstrength = np.zeros((nums, nums))\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pairs[0]] = x0[i]\n",
    "\t\tfor j in range(nums):\n",
    "\t\t\tiXtest[:, pairs[1]] = x0[j]\n",
    "\t\t\tselem = simu.eval(feed_dict={X:iXtest})\n",
    "\t\t\tstrength[i, j] = selem - felem1[i] - felem2[j] + zelem\n",
    "\treturn strength\n",
    "\n",
    "def get_2interactions(tXtest, nums, simu, pairs):\n",
    "\tiXtest = tXtest.copy()\n",
    "\tzelem = simu.eval(feed_dict={X:iXtest})\n",
    "\tfelem1 = np.zeros((nums, 1))\n",
    "\tfelem2 = np.zeros((nums, 1))\n",
    "\tx0 = np.linspace(0, 1, nums)\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pairs[0]] = x0[i]\n",
    "\t\tfelem1[i] = simu.eval(feed_dict={X:iXtest})\n",
    "\t\tiXtest = tXtest.copy()\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pairs[1]] = x0[i]\n",
    "\t\tfelem2[i] = simu.eval(feed_dict={X:iXtest})\n",
    "\t\tiXtest = tXtest.copy()\n",
    "\tstrength = 0\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pairs[0]] = x0[i]\n",
    "\t\tfor j in range(nums):\n",
    "\t\t\tiXtest[:, pairs[1]] = x0[j]\n",
    "\t\t\tselem = simu.eval(feed_dict={X:iXtest})\n",
    "\t\t\tstrength = strength + np.power(selem - felem1[i] - felem2[j] + zelem, 2)\n",
    "\tstrength = np.sqrt(strength * 1.0 / (nums * nums))\n",
    "\treturn strength\n",
    "\n",
    "def get_3interactions(tXtest, nums, simu, pairs):\n",
    "\tiXtest = tXtest.copy()\n",
    "\tzelem = simu.eval(feed_dict={X:iXtest})\n",
    "\tfelem1 = np.zeros((nums, 1))\n",
    "\tfelem2 = np.zeros((nums, 1))\n",
    "\tfelem3 = np.zeros((nums, 1))\n",
    "\tselem1 = np.zeros((nums, nums))\n",
    "\tselem2 = np.zeros((nums, nums))\n",
    "\tselem3 = np.zeros((nums, nums))\n",
    "\tx0 = np.linspace(0, 1, nums)\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pairs[0]] = x0[i]\n",
    "\t\tfelem1[i] = simu.eval(feed_dict={X:iXtest})\n",
    "\t\tiXtest = tXtest.copy()\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pairs[1]] = x0[i]\n",
    "\t\tfelem2[i] = simu.eval(feed_dict={X:iXtest})\n",
    "\t\tiXtest = tXtest.copy()\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pairs[2]] = x0[i]\n",
    "\t\tfelem3[i] = simu.eval(feed_dict={X:iXtest})\n",
    "\t\tiXtest = tXtest.copy()\n",
    "\t\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pairs[0]] = x0[i]\n",
    "\t\tfor j in range(nums):\n",
    "\t\t\tiXtest[:, pairs[1]] = x0[j]\n",
    "\t\t\tselem1[i, j] = simu.eval(feed_dict={X:iXtest})\n",
    "\t\tiXtest = tXtest.copy()\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pairs[0]] = x0[i]\n",
    "\t\tfor j in range(nums):\n",
    "\t\t\tiXtest[:, pairs[2]] = x0[j]\n",
    "\t\t\tselem2[i, j] = simu.eval(feed_dict={X:iXtest})\n",
    "\t\tiXtest = tXtest.copy()\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pairs[1]] = x0[i]\n",
    "\t\tfor j in range(nums):\n",
    "\t\t\tiXtest[:, pairs[2]] = x0[j]\n",
    "\t\t\tselem3[i, j] = simu.eval(feed_dict={X:iXtest})\n",
    "\t\tiXtest = tXtest.copy()\n",
    "\n",
    "\tstrength = 0\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pairs[0]] = x0[i]\n",
    "\t\tfor j in range(nums):\n",
    "\t\t\tiXtest[:, pairs[1]] = x0[j]\n",
    "\t\t\tfor k in range(nums):\n",
    "\t\t\t\tiXtest[:, pairs[2]] = x0[k]\n",
    "\t\t\t\ttelem = simu.eval(feed_dict={X:iXtest})\n",
    "\t\t\t\tstemp = telem - selem1[i, j] - selem2[i, k] - selem3[j, k] + \\\n",
    "\t\t\t\tfelem1[i] + felem2[j] + felem3[k] - zelem\n",
    "\t\t\t\tstrength = strength + np.power(stemp, 2)\n",
    "\n",
    "\tstrength = np.sqrt(strength * 1.0 / (np.power(nums, 3)))\n",
    "\treturn strength\n",
    "\n",
    "def get_4interactions(tXtest, nums, simu, spairs):\n",
    "\tiXtest = tXtest.copy()\n",
    "\tstrength = 0\n",
    "\tx0 = np.linspace(0, 1, nums)\n",
    "\tpairs = sorted(spairs)\n",
    "\tfor i in range(nums):\n",
    "\t\tiXtest[:, pairs[0]] = x0[i]\n",
    "\t\tfor j in range(nums):\n",
    "\t\t\tiXtest[:, pairs[1]] = x0[j]\n",
    "\t\t\tfor k in range(nums):\n",
    "\t\t\t\tiXtest[:, pairs[2]] = x0[k]\n",
    "\t\t\t\tfor l in range(nums):\n",
    "\t\t\t\t\tiXtest[:, pairs[3]] = x0[l]\n",
    "\t\t\t\t\tselem = simu.eval(feed_dict={X:iXtest})\n",
    "\t\t\t\t\tstemp = selem + zzelem - ffelem[pairs[0]] - \\\n",
    "\t\t\t\t\tffelem[pairs[1]] - ffelem[pairs[2]] - ffelem[pairs[3]] + \\\n",
    "\t\t\t\t\tsselem[pairs[0], pairs[1]] + sselem[pairs[0], pairs[2]] + \\\n",
    "\t\t\t\t\tsselem[pairs[0], pairs[3]] + sselem[pairs[1], pairs[2]] + \\\n",
    "\t\t\t\t\tsselem[pairs[1], pairs[3]] + sselem[pairs[2], pairs[3]] - \\\n",
    "\t\t\t\t\tttelem[pairs[0], pairs[1], pairs[2]] - ttelem[pairs[0], pairs[1], pairs[3]] - \\\n",
    "\t\t\t\t\tttelem[pairs[0], pairs[2], pairs[3]] - ttelem[pairs[1], pairs[2], pairs[3]]\n",
    "\t\t\t\t\tstrength = strength + np.power(stemp, 2)\n",
    "\tstrength = np.sqrt(strength * 1.0 / (np.power(nums, 4)))\n",
    "\treturn strength\n",
    "\n",
    "n_variables = 10\n",
    "samples_per_var = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-4a2a2bd216c3>\", line 2, in <module>\n",
      "    tf.set_random_seed(0)\n",
      "AttributeError: module 'tensorflow' has no attribute 'set_random_seed'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1806, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'AttributeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\inspect.py\", line 1480, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\inspect.py\", line 1438, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\inspect.py\", line 730, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 936, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 655, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-4a2a2bd216c3>\", line 2, in <module>\n",
      "    tf.set_random_seed(0)\n",
      "AttributeError: module 'tensorflow' has no attribute 'set_random_seed'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1806, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'AttributeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\LG\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\LG\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'set_random_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "np.random.seed(31)\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "trainingData = pd.DataFrame(pd.read_csv('./friedman_training.csv'))\n",
    "testingData = pd.DataFrame(pd.read_csv('./friedman_testing.csv'))\n",
    "\n",
    "X_train = trainingData.iloc[:, 1:-1].values\n",
    "y_train = trainingData.iloc[:, -1].values.flatten()\n",
    "X_test = testingData.iloc[:, 1:-1].values\n",
    "y_test = testingData.iloc[:, -1].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "n_inputs = n_variables\n",
    "n_hidden1 = 2\n",
    "n_hidden2 = 2\n",
    "n_hidden3 = 2\n",
    "n_hidden4 = 2\n",
    "n_hidden5 = 2\n",
    "n_hidden6 = 2\n",
    "n_hidden7 = 2\n",
    "n_hidden8 = 2\n",
    "n_hidden9 = 2\n",
    "n_hidden10 = 2\n",
    "n_hidden11 = 7\n",
    "n_hidden22 = 8\n",
    "n_hidden33 = 8\n",
    "n_hidden44 = 6\n",
    "n_hidden55 = 9\n",
    "n_hidden66 = 7\n",
    "n_hidden77 = 5\n",
    "n_hidden88 = 10\n",
    "n_hidden99 = 12\n",
    "n_hidden1010 = 13\n",
    "n_outputs = 1\n",
    "g_scale = 1\n",
    "thresh = 0.5\n",
    "dropout_rate = 0.05\n",
    "n_hiddens = n_hidden1 + n_hidden2 + n_hidden3 + n_hidden4 + n_hidden5 + n_hidden6 + n_hidden7 + n_hidden8 + n_hidden9 + n_hidden10\n",
    "elems_scale = [0.01] * n_hiddens\n",
    "g_scalevec = tf.constant(elems_scale)\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "X = tf.placeholder(tf.float32, (None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.float32, (None), name = 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('dnn'):\n",
    "\thidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name='hidden1')\n",
    "\thidden2 = tf.layers.dense(X, n_hidden2, activation=tf.nn.relu, name='hidden2')\n",
    "\thidden3 = tf.layers.dense(X, n_hidden3, activation=tf.nn.relu, name='hidden3')\n",
    "\thidden4 = tf.layers.dense(X, n_hidden4, activation=tf.nn.relu, name='hidden4')\n",
    "\thidden5 = tf.layers.dense(X, n_hidden5, activation=tf.nn.relu, name='hidden5')\n",
    "\thidden6 = tf.layers.dense(X, n_hidden6, activation=tf.nn.relu, name='hidden6')\n",
    "\thidden7 = tf.layers.dense(X, n_hidden7, activation=tf.nn.relu, name='hidden7')\n",
    "\thidden8 = tf.layers.dense(X, n_hidden8, activation=tf.nn.relu, name='hidden8')\n",
    "\thidden9 = tf.layers.dense(X, n_hidden9, activation=tf.nn.relu, name='hidden9')\n",
    "\thidden10 = tf.layers.dense(X, n_hidden10, activation=tf.nn.relu, name='hidden10')\n",
    "\thidden1_1 = tf.layers.dense(hidden1, n_hidden11, activation=tf.nn.relu, name='hidden1_1')\n",
    "\thidden1_1drop = tf.layers.dropout(hidden1_1, dropout_rate, training=training)\n",
    "\thidden1_2 = tf.layers.dense(hidden2, n_hidden22, activation=tf.nn.relu, name='hidden1_2')\n",
    "\thidden1_2drop = tf.layers.dropout(hidden1_2, dropout_rate, training=training)\n",
    "\thidden1_3 = tf.layers.dense(hidden3, n_hidden33, activation=tf.nn.relu, name='hidden1_3')\n",
    "\thidden1_3drop = tf.layers.dropout(hidden1_3, dropout_rate, training=training)\n",
    "\thidden1_4 = tf.layers.dense(hidden4, n_hidden44, activation=tf.nn.relu, name='hidden1_4')\n",
    "\thidden1_4drop = tf.layers.dropout(hidden1_4, dropout_rate, training=training)\n",
    "\thidden1_5 = tf.layers.dense(hidden5, n_hidden55, activation=tf.nn.relu, name='hidden1_5')\n",
    "\thidden1_5drop = tf.layers.dropout(hidden1_5, dropout_rate, training=training)\n",
    "\thidden1_6 = tf.layers.dense(hidden6, n_hidden66, activation=tf.nn.relu, name='hidden1_6')\n",
    "\thidden1_6drop = tf.layers.dropout(hidden1_6, dropout_rate, training=training)\n",
    "\thidden1_7 = tf.layers.dense(hidden7, n_hidden77, activation=tf.nn.relu, name='hidden1_7')\n",
    "\thidden1_7drop = tf.layers.dropout(hidden1_7, dropout_rate, training=training)\n",
    "\thidden1_8 = tf.layers.dense(hidden8, n_hidden88, activation=tf.nn.relu, name='hidden1_8')\n",
    "\thidden1_8drop = tf.layers.dropout(hidden1_8, dropout_rate, training=training)\n",
    "\thidden1_9 = tf.layers.dense(hidden9, n_hidden99, activation=tf.nn.relu, name='hidden1_9')\n",
    "\thidden1_9drop = tf.layers.dropout(hidden1_9, dropout_rate, training=training)\n",
    "\thidden1_10 = tf.layers.dense(hidden10, n_hidden1010, activation=tf.nn.relu, name='hidden1_10')\n",
    "\thidden1_10drop = tf.layers.dropout(hidden1_10, dropout_rate, training=training)\n",
    "\thidden_cat = tf.concat([hidden1_1drop, hidden1_2drop], 1)\n",
    "\thidden_cat = tf.concat([hidden_cat, hidden1_3drop], 1)\n",
    "\thidden_cat = tf.concat([hidden_cat, hidden1_4drop], 1)\n",
    "\thidden_cat = tf.concat([hidden_cat, hidden1_5drop], 1)\n",
    "\thidden_cat = tf.concat([hidden_cat, hidden1_6drop], 1)\n",
    "\thidden_cat = tf.concat([hidden_cat, hidden1_7drop], 1)\n",
    "\thidden_cat = tf.concat([hidden_cat, hidden1_8drop], 1)\n",
    "\thidden_cat = tf.concat([hidden_cat, hidden1_9drop], 1)\n",
    "\thidden_cat = tf.concat([hidden_cat, hidden1_10drop], 1)\n",
    "\thidden_cat_drop = tf.layers.dropout(hidden_cat, dropout_rate, training=training)\n",
    "\tlogits = tf.layers.dense(hidden_cat_drop, n_outputs, name='outputs')\n",
    "\tsimu = tf.reduce_mean(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_h1 = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "W_h2 = tf.get_default_graph().get_tensor_by_name(\"hidden2/kernel:0\")\n",
    "W_h3 = tf.get_default_graph().get_tensor_by_name(\"hidden3/kernel:0\")\n",
    "W_h4 = tf.get_default_graph().get_tensor_by_name(\"hidden4/kernel:0\")\n",
    "W_h5 = tf.get_default_graph().get_tensor_by_name(\"hidden5/kernel:0\")\n",
    "W_h6 = tf.get_default_graph().get_tensor_by_name(\"hidden6/kernel:0\")\n",
    "W_h7 = tf.get_default_graph().get_tensor_by_name(\"hidden7/kernel:0\")\n",
    "W_h8 = tf.get_default_graph().get_tensor_by_name(\"hidden8/kernel:0\")\n",
    "W_h9 = tf.get_default_graph().get_tensor_by_name(\"hidden9/kernel:0\")\n",
    "W_h10 = tf.get_default_graph().get_tensor_by_name(\"hidden10/kernel:0\")\n",
    "W_cat = tf.concat([W_h1, W_h2], 1)\n",
    "W_cat = tf.concat([W_cat, W_h3], 1)\n",
    "W_cat = tf.concat([W_cat, W_h4], 1)\n",
    "W_cat = tf.concat([W_cat, W_h5], 1)\n",
    "W_cat = tf.concat([W_cat, W_h6], 1)\n",
    "W_cat = tf.concat([W_cat, W_h7], 1)\n",
    "W_cat = tf.concat([W_cat, W_h8], 1)\n",
    "W_cat = tf.concat([W_cat, W_h9], 1)\n",
    "W_cat = tf.concat([W_cat, W_h10], 1)\n",
    "W_rcat = tf.transpose(W_cat)\n",
    "#W_tcat = tf.reshape(W_rcat, [n_variables, n_hiddens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ith tf.name_scope('loss'):\n",
    "\tbase_loss = tf.reduce_mean(tf.squared_difference(y, tf.transpose(logits)))\n",
    "\treg_losses = custom_group_regularization_player(W_rcat, g_scalevec)\n",
    "\tloss = tf.add(base_loss, reg_losses, name=\"loss\")\n",
    "learning_rate = 0.1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "epsilon=1e-08\n",
    "with tf.name_scope('train'):\n",
    "\toptimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, beta1 = beta1, beta2 = beta2, epsilon = epsilon)\n",
    "\ttraining_op = optimizer.minimize(loss)\n",
    "with tf.name_scope('eval'):\n",
    "\taccuracy = tf.losses.mean_squared_error(y, tf.transpose(logits))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "batch_size = 300\n",
    "train_samples_size = X_train.shape[0]\n",
    "test_samples_size = X_test.shape[0]\n",
    "test_cnt = 10\n",
    "test_errs = np.zeros((test_cnt, 1))\n",
    "m_errs = np.zeros((test_samples_size, 1))\n",
    "m_frac = np.zeros((test_cnt, n_variables))\n",
    "m_intstrength = np.zeros((test_cnt, 6))\n",
    "m_interactions = np.zeros((test_cnt, 3*nums, 3*nums))\n",
    "conncnt = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "\tinit.run()\n",
    "\tfor epoch in range(n_epochs):\n",
    "\t\tfor i in range(train_samples_size//batch_size):\n",
    "\t\t\tbatch_index = np.random.choice(train_samples_size, batch_size, replace=False)\n",
    "\t\t\tX_batch = X_train[batch_index, :]\n",
    "\t\t\ty_batch = y_train[batch_index]\n",
    "\t\t\tsess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "\t\tif epoch % 5 == 0:\n",
    "\t\t\tacc_train = accuracy.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "\t\t\tacc_test = accuracy.eval(feed_dict={X:X_test, y:y_test})\n",
    "\t\t\tprint (epoch, 'train error:', np.sqrt(acc_train), 'test error:', np.sqrt(acc_test))\n",
    "\t\tif epoch > n_epochs - test_cnt - 1:\n",
    "\t\t\tm_logits = logits.eval(feed_dict={X:X_test})\n",
    "\t\t\tm_errs = m_errs + (np.transpose(m_logits) - y_test)\n",
    "\t\t\ttest_errs[n_epochs - epoch - 1] = accuracy.eval(feed_dict={X:X_test, y:y_test})\n",
    "\t\t\tiXtest = X_test.copy()\n",
    "\t\t\tm_interactions[n_epochs - epoch - 1, :, :] = get_2importance(iXtest, 3*nums, simu, [0, 1])\n",
    "\n",
    "\t\t\tiXtest = X_test.copy()\n",
    "\t\t\tm_intstrength[n_epochs - epoch - 1, 0] = get_2interactions(iXtest, nums, simu, [0, 1])\n",
    "\t\t\tfor pid in range(0, 5):\n",
    "\t\t\t\tiXtest = X_test.copy()\n",
    "\t\t\t\tm_intstrength[n_epochs - epoch - 1, pid + 1] = get_1interaction(iXtest, nums, simu, pid)\n",
    "\tsave_path = saver.save(sess, './my_f7_model_final.ckpt')\n",
    "\n",
    "\tprint (epoch, 'train error:', np.sqrt(acc_train), 'test error:', np.sqrt(acc_test))\n",
    "\thm_errs = np.mean(test_errs)\n",
    "\thvar_err = np.mean(np.power(test_errs, 2)) - np.power(hm_errs, 2)\n",
    "\tprint (epoch, 'test mean loglikelihood:', -0.5 *np.log(2*np.pi) - 0.5 * hm_errs, 'test standard deviation by neg loglikelihood', 0.5 * np.sqrt(hvar_err))\n",
    "\tm_errs = m_errs * 1.0 / test_cnt\n",
    "\tmean_err = np.mean(np.power(m_errs, 2))\n",
    "\tvar_err = 1.0 / test_samples_size * (np.mean(np.power(m_errs, 4)) - np.power(mean_err, 2))\n",
    "\ttvar_err = np.sqrt(mean_err) - np.sqrt(mean_err - np.sqrt(var_err))\n",
    "\tprint (epoch, 'test mean error:', np.sqrt(mean_err), 'test variance', tvar_err)\n",
    "\tprint np.mean(m_intstrength, 0)\n",
    "\tprint np.std(m_intstrength,0)\n",
    "\n",
    "\tprint m_interactions.shape\n",
    "\tmean_int = np.mean(m_interactions, 0)\n",
    "\tstd_int = np.std(m_interactions, 0)\n",
    "\tplt.matshow(mean_int)\n",
    "\tplt.colorbar()\n",
    "\tplt.show()\n",
    "\tdf = pd.DataFrame(mean_int)\n",
    "\tdf.to_csv(\"mean_interaction.csv\")\n",
    "\tprint (mean_int)\n",
    "\tplt.matshow(std_int)\n",
    "\tplt.colorbar()\n",
    "\tplt.show()\n",
    "\t#print (std_int)\n",
    "\tdt = pd.DataFrame(std_int)\n",
    "\tdt.to_csv(\"mean_deviation.csv\")\n",
    "\tW_mat = W_rcat.eval()\n",
    "\tplt.matshow(W_mat)\n",
    "\tplt.colorbar()\n",
    "\tplt.clim(-1, 1)\n",
    "\tplt.show()\n",
    "\t#print (W_mat)\n",
    "\tinteraction_pruned = [[], [], [], [], [], [], [], [], [], []]\n",
    "\tfraction_score = np.zeros((n_variables, 1))\n",
    "\tprint interaction_pruned\n",
    "\tfor i in range(n_variables):\n",
    "\t\tisum = 0\n",
    "\t\tfor j in range(int(n_hiddens//2)):\n",
    "\t\t\tif ((np.abs(W_mat[2*j, i]) >= thresh) or (np.abs(W_mat[2*j + 1, i]) >= thresh)):\n",
    "\t\t\t\tisum = isum + 1\n",
    "\t\t\t\tinteraction_pruned[j].append(i)\n",
    "\t\tfraction_score[i] = isum * 1.0 / int(n_hiddens//2)\n",
    "\tprint (fraction_score)\n",
    "\tprint interaction_pruned\n",
    "\tiXtest = X_test.copy()\n",
    "\tvariance_order(iXtest, nums, simu)\n",
    "\tpairset = {}\n",
    "\tfor ele in interaction_pruned:\n",
    "\t\tif tuple(ele) not in pairset:\n",
    "\t\t\tiXtest = X_test.copy()\n",
    "\t\t\tif len(ele) == 2:\n",
    "\t\t\t\tval = get_2interactions(iXtest, nums, simu, ele)\n",
    "\t\t\t\tpairset[tuple(ele)] = val\n",
    "\t\t\telif len(ele) == 3:\n",
    "\t\t\t\tval = get_3interactions(iXtest, nums, simu, ele)\n",
    "\t\t\t\tpairset[tuple(ele)] = val\n",
    "\t\t\telif len(ele) == 4:\n",
    "\t\t\t\tval = 0\n",
    "\t\t\t\t#val = get_4interactions(iXtest, nums, simu, ele)\n",
    "\t\t\t\tpairset[tuple(ele)] = val\n",
    "\tfor i in range(int(n_hiddens//2)):\n",
    "\t\tif (len(interaction_pruned[i]) > 5):\n",
    "\t\t\tprint (\"Wow, more than 5 interations\")\n",
    "\t\tif (len(interaction_pruned[i]) > 1):\n",
    "\t\t\tp_subset = list(itertools.combinations(interaction_pruned[i], 2))\n",
    "\t\t\tfor st in p_subset:\n",
    "\t\t\t\tif (len(pairset) >= conncnt):\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tif (tuple(st) not in pairset) and len(pairset) < conncnt:\n",
    "\t\t\t\t\tiXtest = X_test\n",
    "\t\t\t\t\tval = get_2interactions(iXtest, nums, simu, st)\n",
    "\t\t\t\t\tpairset[tuple(st)] = val\n",
    "\t\tif (len(interaction_pruned[i]) > 2):\n",
    "\t\t\tp_subset = list(itertools.combinations(interaction_pruned[i], 3))\n",
    "\t\t\tfor st in p_subset:\n",
    "\t\t\t\tif (len(pairset) >= conncnt):\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tif (tuple(st) not in pairset) and len(pairset) < conncnt:\n",
    "\t\t\t\t\tiXtest = X_test\n",
    "\t\t\t\t\tval = get_3interactions(iXtest, nums, simu, st)\n",
    "\t\t\t\t\tpairset[tuple(st)] = val\n",
    "\t\tif (len(interaction_pruned[i]) > 3):\n",
    "\t\t\tp_subset = list(itertools.combinations(interaction_pruned[i], 4))\n",
    "\t\t\tfor st in p_subset:\n",
    "\t\t\t\tif len(pairset) >= conncnt:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tif (tuple(st) not in pairset) and len(pairset) < conncnt:\n",
    "\t\t\t\t\tiXtest = X_test\n",
    "\t\t\t\t\tval = 0\n",
    "\t\t\t\t\t#val = get_4interactions(iXtest, nums, simu, st)\n",
    "\t\t\t\t\tpairset[tuple(st)] = val\n",
    "\tlstrength = sorted( ((v,k) for k,v in pairset.iteritems()), reverse=True)\n",
    "\tprint lstrength"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
